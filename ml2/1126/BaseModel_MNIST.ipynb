{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "r4e_U5zYaoYa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "l5ObFPzTbdaJ"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "validation_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(dataset=training_dataset, batch_size=100, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=100, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "5w2eR5IAbMHS"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # 32px 이었다가, conv를 거치면서 절반으로 감소\n",
        "    self.conv1 = nn.Conv2d(1, 16, 3, 1, padding=1)\n",
        "    self.conv2 = nn.Conv2d(16, 32, 3, 1, padding=1)\n",
        "    self.conv3 = nn.Conv2d(32, 64, 3, 1, padding=1)\n",
        "    self.fc1 = nn.Linear(4*4*64, 500)\n",
        "    self.dropout1 = nn.Dropout(0.5)\n",
        "    self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = x.view(-1, 4*4*64)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.dropout1(x)\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Net().to(device)\n",
        "torch.save(model.state_dict(), 'MNIST_BaseModel_weights.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "3VjPA5Hfa1dp"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfpcyz8tbDX5",
        "outputId": "c26f5784-4d55-425f-b02b-aee59f299d8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===================================================\n",
            "epoch:  1\n",
            "training loss: 1.72446, acc: 37.391998\n",
            "validation loss: 1.55120, acc: 43.720001\n",
            "===================================================\n",
            "epoch:  2\n",
            "training loss: 1.44779, acc: 47.716000\n",
            "validation loss: 1.39370, acc: 49.570000\n",
            "===================================================\n",
            "epoch:  3\n",
            "training loss: 1.33785, acc: 51.681999\n",
            "validation loss: 1.31821, acc: 52.459999\n",
            "===================================================\n",
            "epoch:  4\n",
            "training loss: 1.25203, acc: 55.012001\n",
            "validation loss: 1.27294, acc: 54.060001\n",
            "===================================================\n",
            "epoch:  5\n",
            "training loss: 1.18392, acc: 57.695999\n",
            "validation loss: 1.21749, acc: 56.830002\n",
            "===================================================\n",
            "epoch:  6\n",
            "training loss: 1.12857, acc: 59.782001\n",
            "validation loss: 1.17000, acc: 58.200001\n",
            "===================================================\n",
            "epoch:  7\n",
            "training loss: 1.07812, acc: 61.966000\n",
            "validation loss: 1.13756, acc: 59.720001\n",
            "===================================================\n",
            "epoch:  8\n",
            "training loss: 1.03751, acc: 63.125999\n",
            "validation loss: 1.11344, acc: 60.570000\n",
            "===================================================\n",
            "epoch:  9\n",
            "training loss: 0.99810, acc: 64.706001\n",
            "validation loss: 1.11099, acc: 61.459999\n",
            "===================================================\n",
            "epoch:  10\n",
            "training loss: 0.97338, acc: 65.606003\n",
            "validation loss: 1.09933, acc: 61.610001\n",
            "===================================================\n",
            "epoch:  11\n",
            "training loss: 0.93950, acc: 66.776001\n",
            "validation loss: 1.08968, acc: 61.980000\n",
            "===================================================\n",
            "epoch:  12\n",
            "training loss: 0.91156, acc: 67.781998\n",
            "validation loss: 1.09052, acc: 62.200001\n"
          ]
        }
      ],
      "source": [
        "epochs = 12\n",
        "running_loss_history = []\n",
        "running_correct_history = []\n",
        "validation_running_loss_history = []\n",
        "validation_running_correct_history = []\n",
        "\n",
        "for e in range(epochs):\n",
        "\n",
        "  running_loss = 0.0\n",
        "  running_correct = 0.0\n",
        "  validation_running_loss = 0.0\n",
        "  validation_running_correct = 0.0\n",
        "\n",
        "  for inputs, labels in training_loader:\n",
        "\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    running_correct += torch.sum(preds == labels.data)\n",
        "    running_loss += loss.item()\n",
        "\n",
        "\n",
        "\n",
        "  else:\n",
        "    # 훈련팔 필요가 없으므로 메모리 절약\n",
        "    with torch.no_grad():\n",
        "\n",
        "      for val_input, val_label in validation_loader:\n",
        "\n",
        "        val_input = val_input.to(device)\n",
        "        val_label = val_label.to(device)\n",
        "        val_outputs = model(val_input)\n",
        "        val_loss = criterion(val_outputs, val_label)\n",
        "\n",
        "        _, val_preds = torch.max(val_outputs, 1)\n",
        "        validation_running_loss += val_loss.item()\n",
        "        validation_running_correct += torch.sum(val_preds == val_label.data)\n",
        "\n",
        "\n",
        "    epoch_loss = running_loss / len(training_loader)\n",
        "    epoch_acc = running_correct.float() / len(training_loader)\n",
        "    running_loss_history.append(epoch_loss)\n",
        "    running_correct_history.append(epoch_acc)\n",
        "\n",
        "    val_epoch_loss = validation_running_loss / len(validation_loader)\n",
        "    val_epoch_acc = validation_running_correct.float() / len(validation_loader)\n",
        "    validation_running_loss_history.append(val_epoch_loss)\n",
        "    validation_running_correct_history.append(val_epoch_acc)\n",
        "\n",
        "    print(\"===================================================\")\n",
        "    print(\"epoch: \", e + 1)\n",
        "    print(\"training loss: {:.5f}, acc: {:5f}\".format(epoch_loss, epoch_acc))\n",
        "    print(\"validation loss: {:.5f}, acc: {:5f}\".format(val_epoch_loss, val_epoch_acc))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "951cb00ebd66971857c5880c838618f69a707a5e4d3bee9fba08c4850d7bcc87"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
